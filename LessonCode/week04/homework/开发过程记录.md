# 开发过程记录

在拿到这个题目的时候，我是非常不知所措的，以前做过的题数据量再大也只是1e6左右的数据集，这个直接相当于翻了一千倍不止。

虽然数据量变得非常庞大，但是基本思路还是有的，基本可以划分为三个模块：
1. 文件IO操作
2. 字符串模式匹配算法
3. 多线程

下面来具体看一下，我是如何一步一步优化出来的。

最开始我自己的心里也没有底气，我不知道自己能写到什么程度。甚至不知道自己最开始定的框架是否可行，但是本着先跑出来再优化的原则，还是大胆去写代码了，虽然最后改了好几版做了好几次大的优化。

## 大文件读取如何优化？

是一行一行地读还是一块一块地读？是单线程从头读到尾，还是多线程读取？读取的时候到底怎么计算行号，是最开始读文件的时候就记录还是后面再计算，我到底需要读取多少次文件才能完成工作，读取的过程当中采用什么数据结构存储数据？

### 朴实无华的文件流操作

带着这些问题，我到处查资料，然后写出了第一版代码：
```cpp
int main()
{
    //首先准备keyword的文件
    std::ifstream filekeyword("./Keyword.txt");
    if (!filekeyword)
    {
        std::cerr << "ERROR Opening the file." << std::endl;
        std::cerr << "Stream state: " << std::hex << filekeyword.rdstate() << std::endl;
        return 1;
    }
    std::vector<std::string> keys;
    std::string line;
    while (std::getline(filekeyword, line))
    {
        keys.push_back(line);
    }


    // 打开文件
    std::ifstream file("./testin3.txt");
    if (!file)
    {
        std::cerr << "ERROR Opening the file." << std::endl;
        std::cerr << "Stream state: " << std::hex << file.rdstate() << std::endl;
        return 1;
    }

    std::ofstream fout("./output2.txt", std::ios::out | std::ios::app); // 以追加模式打开
    if (!fout)
    {
        std::cerr << "ERROR Opening the output file." << std::endl;
        return 1;
    }

    // 创建缓冲区，将规定大小的字符串读取到缓冲区中
    const long long bufferSize = 1024 * 1024; // 每次处理1MB
    std::vector<char> buffer(bufferSize); //从文件当中读取的字符串，会包括换行符
    std::vector<long long> lines(bufferSize); //预处理每个字符出现在第几行

    std::streamsize bytesRead;

    long long countline = 1;
    while (true)
    {
        bytesRead = 0;
        for (long long i = 0; i < bufferSize; i++)
        {
            lines[i] = countline;
            if (!file.get(buffer[i])) // 读取失败或到达文件末尾
            {
                break;
            }

            if (buffer[i] == '\n') countline++;


            bytesRead++;
        }

        if (bytesRead == 0) // 没有读取到数据，退出循环
        {
            break;
        }

        //对缓冲区进行处理操作
        //buffer 读取完毕，测试输出到文件output2.txt
        testAc(buffer, lines, keys);


    }

    std::cout << "总共有：" << countline << "行" << std::endl;
    std::cout << "File {\"output.txt\"} has been written done." << std::endl;

    file.close();
    fout.close();

    return 0;
}
```
在上面这个代码当中，我选取的是一个字符一个字符读取文件（效率是非常低下的），但是相对于一行一行读取，这个方法有一个优势，**就是如果在某一个超大文本当中，一个换行符也没有怎么办，显然再用一行一行读取文件的方法就会直接崩溃。** 但是一个字符一个字符读取然后再打包提交到任务当中，就能很好地控制每一个任务的规模。并且在逐字读取的过程当中，也能够直接记录每个字符所在的位置并存储，注意这个位置是绝对位置，也就是说后续不要经过任何计算，直接就可以获得每个匹配串的位置信息。

上述代码有几个缺点。第一个缺点非常明显，就是慢，IO操作相比于cpu的计算是非常非常慢的，也就是说每次读取1MB打包提交到线程池，然后再读取1MB打包提交到线程池，每个线程并发执行。**看上去是并发的，其实不是的**，IO操作很慢，提交任务的速度也慢，而处理模式串的速度是比较快的，这就导致了，执行任务的线程执行完毕之后，依然没有新的任务提交而空等，其他线程也因为任务分配不够快而空等。于是，时间的决定因素还是文件的读取的快慢。

我测试了一下，这个方法用于超大文本的读取，速度是非常糟糕的，需要二十分钟，完成所有操作需要三四十分钟，这还是太恐怖了。于是就有了：

### 内存映射

然后我就想内存操作是很快速的，硬盘的io是很慢的，有没有一种操作能直接提升文件IO的速度呢。
当然是有，这就是文件的**内存映射**技术。通过调用操作系统的API来实现文件在内存中的映射，以接近内存访问的速度访问文件。

于是，就有了下面的代码，不使用文件流的方式读取，而是使用内存映射的方式通过一个指针遍历文件：
```cpp
int main()
{
    //首先准备keyword的文件
  ......
      

    //首先初始化文件路径，直接写会导致路径不匹配
    LPCWSTR widePath = L"testiin2.txt"; //字符匹配不兼容的话就使用宽字符串

    //将要读取的文件进行内存映射
    HANDLE hFile = CreateFile(
        widePath,
        GENERIC_READ,              // 只读权限
        FILE_SHARE_READ,           // 允许其他进程读取
        NULL,                      // 默认安全属性
        OPEN_EXISTING,             // 打开现有文件
        FILE_ATTRIBUTE_NORMAL,     // 正常文件属性
        NULL                       // 没有模板文件
    );
    
    if (hFile == INVALID_HANDLE_VALUE) 
    {
        std::cerr << "Can not open the file {testiin2.txt}." << std::endl;
        return 1;
    }

    // 获取文件大小
    LARGE_INTEGER fileSize;
    GetFileSizeEx(hFile, &fileSize);

    // 创建文件映射
    HANDLE hMapFile = CreateFileMapping(
        hFile,
        NULL,
        PAGE_READONLY,
        0,
        0,
        NULL
    );

    if (hMapFile == NULL) 
    {
        std::cerr << "Can not Create Mapping." << std::endl;
        CloseHandle(hFile);
        return 1;
    }

    // 映射文件
    LPVOID lpBase = MapViewOfFile(
        hMapFile,
        FILE_MAP_READ,
        0,
        0,
        0 // 映射偏移量，为0表示整个文件
    );

    if (lpBase == NULL) 
    {
        std::cerr << "Can not Mapping the file {testiin2.txt}." << std::endl;
        CloseHandle(hMapFile);
        CloseHandle(hFile);
        return 1;
    }
    
    // 现在，lpBase指向了映射的内存区域，可以像操作内存一样操作文件内容
    char* ptr = static_cast<char*>(lpBase);
    
    const long long bufferSize = 1024 * 1024 * 2; //每次处理的数据大小
    std::vector<char> buffer(bufferSize); //从文件当中读取字符，包括换行符
    std::vector<long long> lines(bufferSize); //预处理每一个字符出现在第几行

    long long bytesRead = 0; //记录在文件中处理了多少个字符
    long long countline = 1;


    // 开始计时
    auto start = std::chrono::high_resolution_clock::now();

    while (true)
    {
        long long i = 0;
        for ( i = 0; i < bufferSize; i++)
        {
            if (bytesRead == fileSize.QuadPart) break; //到达文件末尾

            buffer[i] = ptr[bytesRead];
            lines[i] = countline;

            if (buffer[i] == '\n') countline++;

            bytesRead++;
        }

        //提交，最后一个板块的任务，长度可能不及1MB
        if (bytesRead == fileSize.QuadPart) //到达文件末尾
        {
            buffer.resize(i + 1);
            lines.resize(i + 1); //清除掉末尾的无效数据

            // 提交任务
            results.push_back(pool.submit(testAc, buffer, lines, acTop));

            break;
        }
        else
        {
            //提交任务
            results.push_back(pool.submit(testAc, buffer, lines, acTop));
        }

    }

    // 结束计时
    auto end = std::chrono::high_resolution_clock::now();

    // 计算持续时间
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    // 输出结果
    std::cout << "操作耗时: " << duration.count() << " 毫秒" << std::endl;


    // 解除映射
    UnmapViewOfFile(lpBase);
    CloseHandle(hMapFile);
    CloseHandle(hFile);
    

    //pool.shutdown();

    return 0;
}
```
效果非常显著，读取文件的时间优化来到7min左右，整个操作的执行时间需要20min。显然还是慢了。操作系统貌似也只能帮我到这个地步了。

仔细检查代码，就会发现代码当中有几个地方非常糟糕：
1. 文件的读取依然是单线程的，也就是任务的提交速度依然不够快，依然可能造成其余线程阻塞。

2. 提交任务的方式不合理，比如如下代码：
```cpp
 //提交任务
 results.push_back(pool.submit(testAc, buffer, lines, acTop));
```
这里面有两个参数一个是主串`buffer`，一个是记录位置信息的`lines` ，在传递参数的时候传递的是副本，而且每次最少解析1MB的数据，也就是每次最少需要2MB的内存空间，看上去好像还可以，但是线程比较多的时候，那个内存的分配与释放，无论是时间还是空间上的开销，都是非常糟糕的，甚至还可能因为内存中划分不出这么大的连续空间而导致崩溃。

3. 看上去只是读取一遍文件，其实还是读取了两次。一次是读取内容到缓冲区并提交副本，一次是进行字符串匹配的时候，又遍历了一次。


### 多线程读取文件，并在读取的时候就顺便完成字符串匹配

多线程读取文件的时候，就需要考虑位置如何进行存储和计算的问题了，同时还要考虑块与块之间有没有可能出现模式串（即边界处理）。

**1. 首先解决位置如何计算** 

多线程当中是无法一次性得到绝对位置的，我们只能暂且计算相对位置。并且记录最大的相对位置。
计算方法为：每一个任务中首先定义一个 counline 变量，初始值为0，每次碰到换行符就自增 1 。这样相对位置就轻松算出来了。

刚开始我还考虑了很多，比如分块的位置属于哪一种情况，如果某一块的第一个字符就是换行符怎么办，后来总结出来所有情况都可以归为一种情况，就是上面这样的算法。

有了相对位置，如何转换成绝对位置呢？，也很简单，把前面出现过的最大行号都累加起来，然后再加上相对位置。可是行号从1开始的，是的，所以累加处理之前，处理累加的变量初始值应该设置为1。

如何知道累加顺序呢？其实在每次提交任务的时候，这个顺序就被隐含在了`result`数组里面，每个任务的提交顺序就是数组里面的下标+1。
```cpp
//每一个线程的返回值都存储在vector当中
//隐式的记录里面的每一个任务的index, 计算绝对路径可以使用
std::vector< std::future< std::unordered_map<std::string, std::vector<long long>> > > results;

// 提交任务
results.push_back(pool.submit(testAc, buffer, lines, acTop));
```


每一次执行完匹配算法，就会返回一个值，这个值是一个unordered_map的数据结构，大致记录的信息如下：

```cpp
 = {
    {keyword1, {pos1, pos 2, po3 3, ......, pos n1}},
    {keyword2, {pos1, pos 2, po3 3, ......, pos n2}},
     //keyword3 is not exits
     ......
    {keyword m, {pos1, pos 2, po3 3, ......, pos nm}},
    {"__MAX__LINE__", {(long long) maxline}}
}
```

每一个数据块的相对最大的行号就是存储在` {"__MAX__LINE__", {(long long) maxline}}` 这样一个键值对当中。


**2. 如何边界处理** 
这个代码稍微有些复杂，但是我还是实现了。不能直接使用传统的模式匹配算法去查看有没有对上。我想的是一种类似于对齐的方法。

假设块1 与 块2，之间可能有模式串被分割导致统计的时候被漏掉，算法如下：
1. 定位块2 的第一个字符char c
2. 遍历模式串：
    2.1 当前模式串是否存在字符 c , 存在并且出现的位置不能在模式串的首位。（因为要满足跨边界的条件）
    2.2 找到模式串中满足条件的 c 的位置，向左向右依次匹配，碰到换行符就忽略，实现跨行匹配。向右匹配的时候要一边记录相对位置。如果所有位置匹配成功，就需要将相对位置插入到答案当中，并且跳出。如果发现有一个字符不匹配，就跳出，在模式串中查找下一个符合条件的字符 c ，然后重复2.2的操作，直到越界。


**3. 多线程方式如何提交任务以提高效率**

每次提交任务的之后只用打包起始指针、文件块的大小以及公共的字典树（Tire树是为字符串的模式匹配算法准备的，后续会讲到）。

只是打包指针减少了创建和传递副本的工作量，减少了多余的读取次数，下次读取也就是第一次读取文件内容的时候是在文件进行模式串匹配的时候。

传递文件块的大小，主要是考虑到最后一个块，它的长度是不确定的。

公共字典树，多模式匹配算法我选择AC自动机，里面构建了带有Fail指针的Tire树。那么问题来了，我需要为每一个任务都构建这样一个Tire树吗，明明模式串是全局的，那为什么由模式串构建的Tire树不能是全局的呢？当然有解决办法，办法就是创建一个构建好的Ac自动机，然后所有任务自己也有一个AC自动机，但是任务当中的自动机浅拷贝公共的字典树，也就是root指针只需要指向已经创建好的自动机即可。这样大大减少了Tire树以及AC自动机构建的开销。

以下便是最终版的优化代码了：
```cpp
#include"AcAutomation.h"
#include"threadpool3.cpp"
#include<iostream>
#include<string>
#include<fstream>
#include<vector>
#include<sstream>
#include <chrono>
#include<windows.h>

//cerr相比于cout更加及时


//任务打包函数
//返回值是 <keyword, keyword在某个文件块中的相对行号>   --不要忘记转换成绝对行号
std::unordered_map<std::string, std::vector<long long>>
TaskPack(const char* const ptr, const size_t bufferSize, const AcAutomation& acTop)
{
    AcAutomation ac(acTop); //浅拷贝
    
    //调用AC自动机 并直接返回结果
    return ac.AcSearch(ptr, bufferSize);
}






int main()
{
	//首先准备keyword文件，先初始化AC自动机中的Tire树
    std::ifstream filekeyword("./keyword.txt");
    if (!filekeyword)
    {
        std::cerr << "ERROR Opening the file." << std::endl;
        std::cerr << "Stream state: " << std::hex << filekeyword.rdstate() << std::endl;
        return 1;
    }
    std::vector<std::string> keys;
    std::string line;
    while (std::getline(filekeyword, line))
    {
        keys.push_back(line);
    }

    filekeyword.close();

    //获取关键字之后就可以创建AC自动机了，避免自动机中的Tire树重复构建
    //之后所有的AC自动机都将浅拷贝这一份数据
    AcAutomation acTop;
    acTop.AcInit(keys);

    //创建一个具有*个线程的线程池
    ThreadPool pool(2);
    pool.init();

    //每一个线程的返回值都存储在vector当中
    //隐式的记录里面的每一个任务的index, 计算绝对路径可以使用
    std::vector< std::future< std::unordered_map<std::string, std::vector<long long>> > > results;

    //首先初始化文件路径，直接写会导致路径不匹配
    //LPCWSTR widePath = L"testin_min.txt"; //字符匹配不兼容的话就使用宽字符串
    //LPCWSTR widePath = L"testbug.txt";
    //LPCWSTR widePath = L"testXML.txt"; 
    LPCWSTR widePath = L"input.xml"; 

    //将要读取的文件进行内存映射
    HANDLE hFile = CreateFile(
        widePath,                  // 文件路径
        GENERIC_READ,              // 只读权限
        FILE_SHARE_READ,           // 允许其他进程读取
        NULL,                      // 默认安全属性
        OPEN_EXISTING,             // 打开现有文件
        FILE_ATTRIBUTE_NORMAL,     // 正常文件属性
        NULL                       // 没有模板文件
    );

    if (hFile == INVALID_HANDLE_VALUE)
    {
        std::cerr << "Can not open the file {testiin2.txt}." << std::endl;
        return 1;
    }

    // 获取文件大小 fileSize.QuadPart
    LARGE_INTEGER fileSize;
    GetFileSizeEx(hFile, &fileSize);

    // 创建文件映射
    HANDLE hMapFile = CreateFileMapping(
        hFile,
        NULL,
        PAGE_READONLY,
        0,
        0,
        NULL
    );

    //创建文件映射不成功
    if (hMapFile == NULL)
    {
        std::cerr << "Can not Create Mapping." << std::endl;
        CloseHandle(hFile);
        return 1;
    }

    // 映射文件 得到指向文件开头的指针lpBase
    LPVOID lpBase = MapViewOfFile(
        hMapFile,
        FILE_MAP_READ,
        0,
        0,
        0 // 映射偏移量，为0表示整个文件
    );

    if (lpBase == NULL)
    {
        std::cerr << "Can not Mapping the file {testin3.txt}." << std::endl;
        CloseHandle(hMapFile);
        CloseHandle(hFile);
        return 1;
    }

    // 现在，lpBase指向了映射的内存区域，可以像操作内存一样操作文件内容
    char* ptr = static_cast<char*>(lpBase);

    const size_t bufferSize = 1024 * 1024 * 64; //每次处理的数据大小
    int n = 0; //控制指针的偏移量，ptr + n * 



    // 开始计时
    auto start = std::chrono::high_resolution_clock::now();


    //打包任务
    //每次传递的参数只是一个指针和文件块的大小，还有公共的acTop
    while (true)
    {
        if ((n + 1) * bufferSize > fileSize.QuadPart) //文件末尾的块的大小不足bufferSize
        {
            results.push_back(pool.submit(TaskPack, (ptr + n * bufferSize),         //读取文件操作的起始指针
                                                    (fileSize.QuadPart - n * bufferSize),   //文件块的大小
                                                     acTop));

            break;  //提交完最后一个任务

        }
        else
        {
            results.push_back(pool.submit(TaskPack, (ptr + n * bufferSize),         //读取文件操作的起始指针
                                                     bufferSize,   //文件块的大小
                                                     acTop));
        }
        n++;
    }



    //动态的检查和处理已经完成的任务
    int completed = 0; //记录已经完成的数量

    const int THREADNUMBER = results.size();
    //建立一个总表，获取所有线程返回的结果
    std::vector< std::unordered_map<std::string, std::vector<long long>> > ans(THREADNUMBER);

    for (int i = 0; i < results.size(); i++)
    {
        ans[i] = results[i].get();//存储第i个任务返回的结果
    }


    //处理返回的结果
    // 用于存储每个关键字的总个数
    std::unordered_map<std::string, int> keywordCounts;
    for (const auto& key : keys) 
    {
        keywordCounts[key] = 0;
    }

    // 遍历ans中的每个unordered_map
    for (const auto& map : ans) 
    {
        // 遍历所有可能的关键字
        for (const auto& kv : keywordCounts) 
        {
            const std::string& keyword = kv.first;
            // 检查当前关键字是否在map中，如果在则累加
            if (map.find(keyword) != map.end()) 
            {
                keywordCounts[keyword] += map.at(keyword).size();
            }
        }
    }


    //边界处理
    for (int i = 1; i < results.size(); i++)
    {
        const char* sp = ptr + bufferSize * i;
        const char c = (*sp); //边界处，后一个文件块的第一个字符
        
        //模式串没有换行符，匹配的时候要忽略主串的换行符
        for (const auto& key : keys)
        {
            size_t pos = 0;
            int cntline = 0;

            while (pos >= 0 && pos < key.size())
            {
                bool lflag = true, rflag = true; //每一次开始新的匹配的时候都默认为true
                int mainl = 1, mainr = 1; //主串偏移量
                int modl = 1, modr = 1; //模式串偏移量

                cntline = 0;

                pos = key.find(c, pos + 1); //返回字符 c 在字符串 key 中pos之后出现的索引位置
                //pos这个位置不能是模式串的首位，否则不符合跨界的条件，所以从下标1开始查找

                if (pos == std::string::npos) //没有在模式串中找到这个字符
                {
                    break; //该模式串无论如何也不会在边界处出现，继续查找下一个模式串
                }

                while (pos - modl >= 0)
                {

                    if (*(sp - mainl) == '\n')
                    {
                        mainl++;
                        continue;
                    }

                    if (key[pos - modl] != *(sp - mainl))
                    {
                        lflag = false;
                        break;
                    }

                    if (pos - modl == 0) break;

                    modl++, mainl++;
                }

                if (lflag == false) continue;

                while (pos + modr < key.size())
                {
                    if (*(sp + mainr) == '\n')
                    {
                        mainr++;
                        cntline++;
                        continue;
                    }

                    if (key[pos + modr] != *(sp + mainr))
                    {
                        rflag = false;
                        break;
                    }

                    if (pos + modr == key.size()) break;

                    modr++, mainr++;
                }

                if (rflag == false) continue;

                if (lflag && rflag) //边界处找到一个匹配
                {
                    //添加数据
                    keywordCounts[key]++;  //数量加1

                    //存储相对位置
                    ans[i].at(key).push_back(cntline);

                }

                //如果没有找到，就继续查找，直到越界，什么也不做

            }

        }

    }

    // 结束计时
    auto end = std::chrono::high_resolution_clock::now();

    // 计算持续时间
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    // 输出结果
    std::cout << "Costs: " << duration.count() << " ms" << std::endl;


    // 输出每个关键字的总个数
    for (const auto& kv : keywordCounts) 
    {
        std::cout << "Keyword: " << kv.first << " ,         Total count: " << kv.second << std::endl;
    }


    char op;
    //询问用户是否输出行号到文件output.txt
    std::cout << "\nDo you want to save the line numbers to the file 'output2.txt'? [Y/N]" << std::endl;
    std::cin >> op;
    switch (op)
    {
    case 'N': std::cout << "Thank you!" << std::endl; break;
    case 'Y':
    {
        //相对行号转换成绝对行号并输出
        size_t Updatelines = 1; //第一块存储的时候也是0开始的，所以整体都要加上1
        std::unordered_map<std::string, std::vector<size_t>> lineNumber;

        for (const auto& map : ans)
        {
            for (const auto& key : map)
            {
                //更新
                if (key.first != "__MAX__LINES__")
                {
                    for (auto& v : key.second)
                    {
                        lineNumber[key.first].push_back(v + Updatelines);
                    }
                }
            }
            auto it = map.find("__MAX__LINES__");
            if (it != map.end()) 
            {
                Updatelines += it->second.at(0);
            }

        }

        // 创建一个ofstream对象，用于写入文件
        // 以追加模式打开文件
        std::ofstream outFile("output2.txt", std::ios::app);

        // 检查文件是否成功打开
        if (!outFile.is_open()) 
        {
            std::cerr << "Failed to open output.txt for writing." << std::endl;
            return 1;
        }

        std::cout << "Please wait for a second......" << std::endl;


        // 遍历unordered_map并写入文件
        for (const auto& pair : lineNumber) 
        {
            const std::string& key = pair.first;
            const std::vector<size_t>& values = pair.second;

            // 写入键（行号标识）
            outFile <<"keyword: " << key << std::endl;

            // 遍历并写入每个行号
            for (long long num : values) 
            {
                outFile <<"line " << num << "\n";
            }
            outFile << std::endl; // 每个键后面的行号写入完毕后换行
        }

        // 关闭文件
        outFile.close();

        std::cout << "The file has been WRITTEN DOWN!" << std::endl;


        break;
    }
    default: std::cout << "INPUT ERROR!" << std::endl; break;
    }


    // 解除映射
    UnmapViewOfFile(lpBase);
    CloseHandle(hMapFile);
    CloseHandle(hFile);


    pool.shutdown();


	return 0;
}
```


## 多模式匹配算法 -- AC自动机

查找资料的过程当中，我对比了很多种模式匹配算法，KMP、BM、AC自动机等等，最终选择了AC自动机，原因如下：
1. 线性的时间复杂度，构建好Tire树之后，对于主串只需要遍历一次就可以求出所有模式串所有出现过的位置。这个算法真的是相当精妙了。
2. 和题意最为契合。

构建一个AC自动机需要以下几步：
1. 根据模式串初始化Trie树
2. 在Trie树上构建Fail指针

对于Trie树上的节点如何设计：
```cpp
//Tire树上的节点
struct AcNode
{
	bool end_flag; //如果读到这个节点能够匹配到一个模式串,就为true,否则为false
	std::unordered_map<char, std::shared_ptr<AcNode>> next; //指向所有子节点的指针集
	std::shared_ptr<AcNode> fail; //fail指针，失配指针
	std::string path;

	AcNode()
	{
		end_flag = false;
		fail = nullptr;
	}

};
```
每一个Trie树的结点都有一个Fail指针，同时有一个标记来表示督导这个节点的时候是否成功匹配一个模式串。如果标记`end_glag`为true，就表示匹配成功，然后从path当中读取模式串的信息。这时候就会出现一个问题，如果“erh” 与“rh”都是模式串怎么办，那 `h` 节点`path`到底应该存储`erh`还是`rh`呢? 答案是`erh` ，那`rh`不就漏掉了吗。实际上在构建Trie树的时候，会出啊下面的结构，只画了一部分：
![](https://oss-liuchengtu.hudunsoft.com/userimg/44/44c26e50cc2801773dc32d8e1e942ab0.jpg)
当`i`节点的子节点失配的时候，就会跳到`i`的Fail指针指向的节点`j` ，然后继续向下匹配；
于是Fail指针就暗含了两个信息：
1. 如果`j`是`i`的`Fail`指针指向的节点，就会有`root->j` 的路径是`root->i`的路径的后缀。
2. 当匹配成功时，可通过Fail指针索引到模式串的后缀，检查模式串的后缀是否也是模式串。

那如果前缀呢，比如`er` 也是模式串，那就更简单了，`er`匹配成功后，`r` 节点的`flag`就会被置为`true`，并且`r`节点的path会保存模式串的信息。

于是，每次匹配成功之后，就会自动通过Fail指针检查后缀是否会有遗漏。
在我的AC自动机当中，由于模式串可能在主串当中跨越多行，于是匹配的过程要忽略换行符并且还要实时更新行号，这样每次匹配成功的时候，就会直接得到相对行号。


## 线程池

线程池主要由两个部分组成：
1. 任务队列
2. 工作队列

工作队列中的线程会从任务队列接受任务，然后开始执行。每一个工作线程在执行任务完毕之后，都会不停地查看任务队列是否有任务，有任务就获取任务再次执行，任务队列为空该工作线程就会被阻塞直到任务队列不为空并且它能够拿到任务。如此循环，直到所有任务都被提交到任务队列并且被安全执行并返回结果，就会关闭线程池。

在线程池中有两个非常重要的函数，第一个是，运算符`()`重载函数，它允许在线程被创建的时候就会不断查询任务队列并自动获取任务并执行。
```cpp
    // 重载()操作
    void operator()()
    {
        std::function<void()> func; // 定义基础函数类func

        bool dequeued; // 是否正在取出队列中元素

        while (!m_pool->m_shutdown)
        {
            {
                // 为线程环境加锁，互访问工作线程的休眠和唤醒
                std::unique_lock<std::mutex> lock(m_pool->m_conditional_mutex);

                // 如果任务队列为空，阻塞当前线程
                if (m_pool->m_queue.empty())
                {
                    m_pool->m_conditional_lock.wait(lock); // 等待条件变量通知，开启线程
                }

                // 取出任务队列中的元素
                dequeued = m_pool->m_queue.dequeue(func);
            }

            // 如果成功取出，执行工作函数
            if (dequeued)
                func();
        }
    }
};
```
这个重载运算在执行`m_threads.at(i) = std::thread(ThreadWorker(this, i)); // 分配工作线程` 的时候会被调用。

还有一个是任务提交函数`submit`，这个真的写得很巧妙了，我当时学习的时候也是看了好半天，研究了好久才搞清楚里面的逻辑，其实线程池的框架搭建并不是难事，但是搭建一个适配性很高的线程池框架就是一个难事。
```cpp
//提交函数，用于提交一个任何返回类型任何参数的函数
//模板声明，它用于定义一个接受一个或多个类型参数的模板函数或模板类
//F&& f和Args&&... args中的&&并非是右值引用意思，而是一种特殊现象，这个现象被称作万能引用
template <typename F, typename... Args>
auto submit(F&& f, Args &&...args) -> std::future<decltype(f(args...))>
{
    // 连接函数和参数定义，特殊函数类型，避免左右值错误
    std::function<decltype(f(args...))()> func = std::bind(std::forward<F>(f), std::forward<Args>(args)...); 

    // 用一个共享指针指向 一个封装好的函数，里面的返回值以及形参列表的值是固定的
    auto task_ptr = std::make_shared<std::packaged_task<decltype(f(args...))()>>(func);

    // lambda函数 共享指针指向的函数 再次封装成void()类型，函数体就是执行这个函数
    std::function<void()> warpper_func = [task_ptr]()
        {
            (*task_ptr)();
        };

    // 队列通用安全封包函数，并压入安全队列
    m_queue.enqueue(warpper_func);

    // 唤醒一个等待中的线程
    m_conditional_lock.notify_one();

    // 返回先前注册的任务指针
    return task_ptr->get_future();
}
```
上述程序实现的主要是一个类似于函数快照的功能，就比如说我想要创建一个任务，这个任务需要调用一个指定的函数，里面的参数也是指定的，然后将这个函数以及指定的参数的值打包成`function<void()>`类型，并压入到队列当中。下次再创建任务的时候，函数的形参的值可能会有所改变，但是这并不影响已经添加到任务队列中的任务，因为我已经保存了这个上次的快照。


对于线程池里面线程数量的设置，这个真是一个令人头疼的问题，线程池的引入本来就是为了提高程序的并发性，提高程序的性能的，但是也要区分**IO密集和CPU密集**两种情况。

当我的线程池写好之后，我分别测试了了一个小一点的文件，一个大概0.55MB，执行时间耗费了330ms左右，如果多线程执行1GB的文件，理论值似乎是线性的，也就是6min，但是实际运行时间竟然达到了恐怖的二十分钟。刚开始我是想不明白的，后来请教了我的操作系统的老师还在网上查找了资料，我发现当我优化了文件的读取操作之后，线程的任务就从IO密集转向了CPU密集，这种情况下，使用多线程其实并不能带来很大的性能提升，如果线程数过多，反而会因为线程之间互相抢占cpu时间片，造成线程切换的开销过大而降低程序的性能。于是我又去网上查找关于线程数设值的科学方法，可惜的是资料很少，理论也不全面，所以我最后只能一次一次测试寻找最优的线程数。

经过我不怎么全面的测试：
![](https://oss-liuchengtu.hudunsoft.com/userimg/45/45f09867b8a682c39ccd1ced0c3654e9.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/71/71bee4a273f49f099e7980ff3382f0a1.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/38/38a120ec3df072b53350f979d652327f.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/18/18951ec4877564bda5b02567b766faf3.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/58/58b244f205e33be649337e67022c7c48.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/c8/c80053f9c955088d882a366fec507015.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/d1/d1c7c940e722f2f871db843d95c03d27.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/6e/6e936fafad503ea2570604a25d3ca3f5.png)
![](https://oss-liuchengtu.hudunsoft.com/userimg/78/78b031630ef26866f4b9c1dc27a7896c.png)

最终决定线程池当中的线程的数量是2，每次处理的文件大小为64MB 。





## 参考资料

由于参考的资料其实挺多的，这里只是列几个对我帮助非常大的参考资料：

[基于C++11实现线程池 - 知乎](https://zhuanlan.zhihu.com/p/367309864)

[AC 自动机 - OI Wiki](https://oi-wiki.org/string/ac-automaton/)

[【全程干货】程序员必备算法！AC自动机算法敏感词匹配算法！动画演示讲解，看完轻松掌握，面试官都被你唬住！！_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1Ag41117YU/?spm_id_from=333.1007.top_right_bar_window_history.content.click)

[Windows内存管理 - 内存映射文件_windows平台 文件映射(内存映射)读写操作-CSDN博客](https://blog.csdn.net/wcyoot/article/details/7363393?ops_request_misc=&request_id=&biz_id=102&utm_term=%E6%96%87%E4%BB%B6%E7%9A%84%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-3-7363393.142^v100^pc_search_result_base6&spm=1018.2226.3001.4187)


## 写在最后

其实我碰到的问题远不止我写出来的问题，但是当程序完成之后，再写文档的时候突然就觉得好几天前碰到的问题都不是问题了。明明在一个星期之前还那么痛苦，根本找不到方向，也不知道会做成什么地步。每一次程序运行的时候，电脑都会啸叫好久，每一次就像犯人一样等待审判的结果。我知道我的程序还有很多的提升空间，我也请教过我学校的老师，找过很多种解决或者优化方案，目前是把我能想到的都用上了，尽管可能对于业界来说，还是太小儿科了，但是相比我自己几天前那个代码，性能提升了不止一星半点。这次的作业让我警觉起来，不跳出舒适区就永远不会有大的突破，所以在今后解决问题的过程当中，会更加注重工程能力的培养，让自己成长起来。























